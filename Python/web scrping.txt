pip install requests
pip install html5lib
pip install bs4


import requests


url = "https://codewithharry.com"
r = requests.get(url)		# r variable has all the HTML code
htmlContent = r.content	# r returns response so if we want the code we write r.content
print(htmlContent)		# printing the code



htmlTexr = r.text
print(htmlText)



import requests
from bs4 import BeautifulSoup
url = "https://codewithharry.com"

r = requests.get(url)
soup = BeautifulSoup(r.content, 'html.parser')

print(soup.prettify())	# to print html in tree structure




soup = BeautifulSoup(htmlContent, 'html.parser')


import requests
from bs4 import BeautifulSoup
url = "https://www.codewithharry.com/videos/python-web-scraping-tutorial-in-hindi"

r = requests.get(url)
soup = BeautifulSoup(r.content, 'html.parser')
for i in soup.find_all("code"):
    print(i.text)
    # We can also do it like this
    # print(i.get_text())


title = soup.title
print(title)



<title>Web Scraping Tutorial using Python and BeautifulSoup in Hindi - Code With Harry</title>


<div>
    <div>
        <code>
            This is file.
        </code>
    </div>
</div>


print(soup.find('p')) 



paras = soup.find_all('p')
print(paras)


for i in paras:
    print(i)


# print(soup.find('p')['class'])


# print(soup.find_all("p", class_="lead"))


# print(soup.find_all(class_="code-toolbar"))



# print(soup.find(id='qna'))

<title>Web Scraping Tutorial using Python and BeautifulSoup in Hindi - Code With Harry</title>


soup.find(‘element’).text
# OR
soup.find(‘element’).get_text()



Web Scraping Tutorial using Python and BeautifulSoup in Hindi - Code With Harry


anchors = soup.find_all('a')



for i in paras:
    print(i['href'])


for i in paras:
    print(i.get('href'))




html = '''
<body>
    <ul>
        <li>This</li>
        <li><a>This</a>This</li>
        <li>This</li>
        <li>This</li>
        <li id="li">This</li>
        <li>    This    </li>
    </ul>
</body>
'''
soup = BeautifulSoup(html, 'html.parser')




<ul>
    <li>This</li>
    <li><a>This</a>This</li>
    <li>This</li>
    <li>This</li>
    <li>This</li>
</ul>




ul = soup.find("ul")
print(ul.contents)





<body>
    <ul>
        <li>This</li>
        <li><a>This</a>This</li>
        <li>This</li>
        <li>This</li>
        <li>This</li>
    </ul>
</body>




ul = soup.find("ul")
for i in ul.children:
	print(i)




ul = soup.find("ul")
print(ul.parent)




print(ul.parent.parent)


ul = soup.find(id="li")
print(ul.next_sibling.next_sibling)


ul = soup.find(id="li")

for j in ul.next_siblings:
    print(j)



for i in ul.previous_siblings:
    print(i)



print(ul.previous_sibling.previous_sibling)




<list_iterator object at 0x000002532ABDF190>




ul = soup.find(id="li")
elem = ul.next_sibling.next_sibling
print(elem)
for i in elem.stripped_strings:
    print(i)



<li>    This    </li>
This




f = open("file.csv", "w")
f.write("Every,word,will,go,in,separate,column\n")
f.write("This,will,go,in,next,row")
f.close()?



with open("file.csv", "w") as f:
    f.write("Every,word,will,go,in,separate,column\n")
    f.write("This,will,go,in,next,row")




python -i filename.py    # write file name with format(.py)




# If you want to scrape a website:
# 1. Use the API
# 2. HTML Web Scraping using some tool like bs4

# Step 0: Install all the requirements
# pip install requests
# pip install bs4
# pip install html5lib

import requests
from bs4 import BeautifulSoup
url = "https://codewithharry.com"

# Step 1: Get the HTML
r = requests.get(url)
htmlContent = r.content
# print(htmlContent)

# Step 2: Parse the HTML
soup = BeautifulSoup(htmlContent, 'html.parser')
# print(soup.prettify)

# Step 3: HTML Tree traversal
# 
# Commonly used types of objects:
# print(type(title)) # 1. Tag
# print(type(title.string)) # 2. NavigableString
# print(type(soup)) # 3. BeautifulSoup
# # 4. Comment
# markup = "<p><!-- this is a comment --></p>"
# soup2 = BeautifulSoup(markup)
# print(type(soup2.p.string))


# Get the title of the HTML page
title = soup.title

# Get all the paragraphs from the page
paras = soup.find_all('p')
# print(paras)

# print(anchors)

# Get first element in the HTML page
# print(soup.find('p') ) 

# Get classes of any element in the HTML page
# print(soup.find('p')['class'])

# find all the elements with class lead
# print(soup.find_all("p", class_="lead"))

# Get the text from the tags/soup
# print(soup.find('p').get_text())
# print(soup.get_text())

# Get all the anchor tags from the page
anchors = soup.find_all('a')
all_links = set()
# Get all the links on the page:
for link in anchors:
    if(link.get('href') != '#'): 
        linkText = "https://codewithharry.com" +link.get('href')
        all_links.add(link)
        # print(linkText)

navbarSupportedContent = soup.find(id='navbarSupportedContent')

# .contents - A tag's children are available as a list
# .children - A tag's children are available as a generator
# for elem in navbarSupportedContent.contents:
#     print(elem)
 
# for item in navbarSupportedContent.strings:
#     print(item)

# for item in navbarSupportedContent.stripped_strings:
#     print(item)

# print(navbarSupportedContent.parent)
# for item in navbarSupportedContent.parents: 
#     print(item.name)

# print(navbarSupportedContent.next_sibling.next_sibling)
# print(navbarSupportedContent.previous_sibling.previous_sibling)

# elem = soup.select('.modal-footer')
# print(elem)
elem = soup.select('#loginModal')[0] 
print(elem)



